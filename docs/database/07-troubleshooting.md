# 07. X·ª≠ l√Ω S·ª± c·ªë Database

## T·ªïng quan

T√†i li·ªáu n√†y m√¥ t·∫£ c√°c s·ª± c·ªë th∆∞·ªùng g·∫∑p khi l√†m vi·ªác v·ªõi SQLite database v√† c√°ch x·ª≠ l√Ω ch√∫ng m·ªôt c√°ch hi·ªáu qu·∫£.

## 1. Connection Issues

### 1.1 Database Locked Error

**L·ªói:** `database is locked`

**Nguy√™n nh√¢n:**
- Nhi·ªÅu process c√πng truy c·∫≠p database
- Connection kh√¥ng ƒë∆∞·ª£c ƒë√≥ng ƒë√∫ng c√°ch
- SQLite kh√¥ng h·ªó tr·ª£ concurrent writes

**Gi·∫£i ph√°p:**
```python
# 1. Th√™m timeout cho connection
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    connect_args={
        "check_same_thread": False,
        "timeout": 30  # Timeout 30 gi√¢y
    }
)

# 2. S·ª≠ d·ª•ng WAL mode
def enable_wal_mode():
    """B·∫≠t WAL mode cho concurrent access"""
    from app.database import engine
    
    with engine.connect() as conn:
        conn.execute(text("PRAGMA journal_mode=WAL"))
        conn.commit()

# 3. ƒê·∫£m b·∫£o ƒë√≥ng connection ƒë√∫ng c√°ch
def safe_database_operation(func):
    """Decorator ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√≥ng connection"""
    def wrapper(*args, **kwargs):
        db = SessionLocal()
        try:
            return func(db, *args, **kwargs)
        finally:
            db.close()
    return wrapper
```

### 1.2 Connection Pool Exhausted

**L·ªói:** `QueuePool limit of size X overflow Y reached`

**Nguy√™n nh√¢n:**
- Qu√° nhi·ªÅu connection ƒë·ªìng th·ªùi
- Connection kh√¥ng ƒë∆∞·ª£c tr·∫£ v·ªÅ pool

**Gi·∫£i ph√°p:**
```python
# 1. TƒÉng pool size
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=3600
)

# 2. S·ª≠ d·ª•ng context manager
from contextlib import contextmanager

@contextmanager
def get_db_session():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# 3. Monitor connection pool
def monitor_connection_pool():
    """Monitor tr·∫°ng th√°i connection pool"""
    pool = engine.pool
    print(f"Pool size: {pool.size()}")
    print(f"Checked out: {pool.checkedout()}")
    print(f"Overflow: {pool.overflow()}")
```

### 1.3 Database File Not Found

**L·ªói:** `no such table` ho·∫∑c `database file not found`

**Nguy√™n nh√¢n:**
- Database file ch∆∞a ƒë∆∞·ª£c t·∫°o
- ƒê∆∞·ªùng d·∫´n kh√¥ng ƒë√∫ng
- Quy·ªÅn truy c·∫≠p file

**Gi·∫£i ph√°p:**
```python
# 1. T·∫°o database v√† tables
def ensure_database_exists():
    """ƒê·∫£m b·∫£o database t·ªìn t·∫°i"""
    import os
    
    # T·∫°o th∆∞ m·ª•c data
    os.makedirs("data", exist_ok=True)
    
    # Kh·ªüi t·∫°o database
    from app.database import init_db
    init_db()
    
    print("‚úÖ Database initialized successfully")

# 2. Ki·ªÉm tra quy·ªÅn truy c·∫≠p
def check_database_permissions():
    """Ki·ªÉm tra quy·ªÅn truy c·∫≠p database"""
    db_path = "./data/sales_management.db"
    
    if not os.path.exists(db_path):
        print(f"‚ùå Database file not found: {db_path}")
        return False
    
    if not os.access(db_path, os.R_OK | os.W_OK):
        print(f"‚ùå No read/write permission for: {db_path}")
        return False
    
    print("‚úÖ Database permissions OK")
    return True
```

## 2. Data Integrity Issues

### 2.1 Foreign Key Constraint Violation

**L·ªói:** `FOREIGN KEY constraint failed`

**Nguy√™n nh√¢n:**
- Tham chi·∫øu ƒë·∫øn record kh√¥ng t·ªìn t·∫°i
- X√≥a record m√† v·∫´n c√≥ foreign key references

**Gi·∫£i ph√°p:**
```python
# 1. Ki·ªÉm tra foreign key tr∆∞·ªõc khi x√≥a
def safe_delete_product(db: Session, product_id: int):
    """X√≥a s·∫£n ph·∫©m an to√†n"""
    # Ki·ªÉm tra c√≥ log n√†o kh√¥ng
    logs_count = db.query(ProductLog).filter(
        ProductLog.product_id == product_id
    ).count()
    
    if logs_count > 0:
        # X√≥a logs tr∆∞·ªõc
        db.query(ProductLog).filter(
            ProductLog.product_id == product_id
        ).delete()
    
    # X√≥a s·∫£n ph·∫©m
    product = db.query(Product).filter(Product.id == product_id).first()
    if product:
        db.delete(product)
        db.commit()
        return True
    
    return False

# 2. S·ª≠ d·ª•ng CASCADE DELETE
def setup_cascade_delete():
    """Thi·∫øt l·∫≠p cascade delete"""
    from app.database import engine
    
    with engine.connect() as conn:
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS product_logs (
                id INTEGER PRIMARY KEY,
                product_id INTEGER NOT NULL,
                action VARCHAR(50) NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (product_id) REFERENCES products(id) ON DELETE CASCADE
            )
        """))
        conn.commit()
```

### 2.2 Unique Constraint Violation

**L·ªói:** `UNIQUE constraint failed`

**Nguy√™n nh√¢n:**
- Th√™m record v·ªõi gi√° tr·ªã unique ƒë√£ t·ªìn t·∫°i
- Update record v·ªõi gi√° tr·ªã unique ƒë√£ t·ªìn t·∫°i

**Gi·∫£i ph√°p:**
```python
# 1. Ki·ªÉm tra unique tr∆∞·ªõc khi insert
def safe_create_product(db: Session, product_data: dict):
    """T·∫°o s·∫£n ph·∫©m an to√†n"""
    # Ki·ªÉm tra SKU unique
    existing = db.query(Product).filter(
        Product.sku == product_data["sku"]
    ).first()
    
    if existing:
        raise ValueError(f"SKU {product_data['sku']} ƒë√£ t·ªìn t·∫°i")
    
    product = Product(**product_data)
    db.add(product)
    db.commit()
    return product

# 2. Upsert (insert or update)
def upsert_product(db: Session, product_data: dict):
    """Insert ho·∫∑c update s·∫£n ph·∫©m"""
    existing = db.query(Product).filter(
        Product.sku == product_data["sku"]
    ).first()
    
    if existing:
        # Update existing
        for key, value in product_data.items():
            setattr(existing, key, value)
        db.commit()
        return existing
    else:
        # Create new
        product = Product(**product_data)
        db.add(product)
        db.commit()
        return product
```

### 2.3 Data Type Mismatch

**L·ªói:** `datatype mismatch`

**Nguy√™n nh√¢n:**
- Ki·ªÉu d·ªØ li·ªáu kh√¥ng ƒë√∫ng
- String thay v√¨ number
- Date format kh√¥ng ƒë√∫ng

**Gi·∫£i ph√°p:**
```python
# 1. Validate data types
def validate_product_data(data: dict):
    """Validate ki·ªÉu d·ªØ li·ªáu s·∫£n ph·∫©m"""
    errors = []
    
    # Validate price
    try:
        price = float(data.get("price", 0))
        if price < 0:
            errors.append("Price must be positive")
    except (ValueError, TypeError):
        errors.append("Price must be a number")
    
    # Validate quantity
    try:
        quantity = int(data.get("quantity", 0))
        if quantity < 0:
            errors.append("Quantity must be non-negative")
    except (ValueError, TypeError):
        errors.append("Quantity must be an integer")
    
    # Validate SKU
    sku = data.get("sku", "")
    if not isinstance(sku, str) or len(sku) > 100:
        errors.append("SKU must be a string with max 100 characters")
    
    return errors

# 2. Safe type conversion
def safe_convert_types(data: dict):
    """Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu an to√†n"""
    converted = {}
    
    for key, value in data.items():
        if key == "price":
            try:
                converted[key] = float(value) if value is not None else 0.0
            except (ValueError, TypeError):
                converted[key] = 0.0
        elif key == "quantity":
            try:
                converted[key] = int(value) if value is not None else 0
            except (ValueError, TypeError):
                converted[key] = 0
        else:
            converted[key] = value
    
    return converted
```

## 3. Performance Issues

### 3.1 Slow Queries

**Tri·ªáu ch·ª©ng:**
- Queries ch·∫°y ch·∫≠m
- Timeout errors
- High CPU usage

**Gi·∫£i ph√°p:**
```python
# 1. Monitor query performance
import time
from functools import wraps

def monitor_slow_queries(threshold: float = 1.0):
    """Decorator ƒë·ªÉ monitor slow queries"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            if execution_time > threshold:
                print(f"‚ö†Ô∏è Slow query: {func.__name__} took {execution_time:.4f}s")
            
            return result
        return wrapper
    return decorator

# 2. Optimize queries
@monitor_slow_queries(threshold=0.5)
def optimized_get_products(db: Session, category: str = None):
    """Query t·ªëi ∆∞u"""
    query = db.query(Product.id, Product.name, Product.sku, Product.price)
    
    if category:
        query = query.filter(Product.category == category)
    
    return query.limit(100).all()

# 3. Use indexes
def create_performance_indexes():
    """T·∫°o indexes cho performance"""
    from app.database import engine
    
    with engine.connect() as conn:
        # Index cho t√¨m ki·∫øm
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_products_sku ON products(sku)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_products_category ON products(category)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_products_price ON products(price)"))
        
        # Index cho logs
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_logs_product_id ON product_logs(product_id)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_logs_created_at ON product_logs(created_at)"))
        
        conn.commit()
```

### 3.2 Memory Issues

**Tri·ªáu ch·ª©ng:**
- High memory usage
- Out of memory errors
- Slow response times

**Gi·∫£i ph√°p:**
```python
# 1. Pagination
def get_products_paginated(db: Session, page: int = 1, per_page: int = 50):
    """L·∫•y s·∫£n ph·∫©m v·ªõi pagination"""
    offset = (page - 1) * per_page
    return db.query(Product).offset(offset).limit(per_page).all()

# 2. Streaming large datasets
def stream_products(db: Session, batch_size: int = 1000):
    """Stream s·∫£n ph·∫©m ƒë·ªÉ ti·∫øt ki·ªám memory"""
    offset = 0
    
    while True:
        products = db.query(Product).offset(offset).limit(batch_size).all()
        
        if not products:
            break
        
        for product in products:
            yield product
        
        offset += batch_size

# 3. Cleanup old data
def cleanup_old_data(db: Session, days: int = 30):
    """X√≥a d·ªØ li·ªáu c≈©"""
    from datetime import datetime, timedelta
    
    cutoff_date = datetime.utcnow() - timedelta(days=days)
    
    # X√≥a logs c≈©
    deleted_logs = db.query(ProductLog).filter(
        ProductLog.created_at < cutoff_date
    ).delete()
    
    db.commit()
    print(f"üóëÔ∏è Deleted {deleted_logs} old logs")
```

## 4. Corruption Issues

### 4.1 Database Corruption

**Tri·ªáu ch·ª©ng:**
- `database disk image is malformed`
- Unexpected errors
- Data inconsistency

**Gi·∫£i ph√°p:**
```python
# 1. Check database integrity
def check_database_integrity():
    """Ki·ªÉm tra t√≠nh to√†n v·∫πn database"""
    from app.database import engine
    
    with engine.connect() as conn:
        result = conn.execute(text("PRAGMA integrity_check"))
        integrity_result = result.fetchone()[0]
        
        if integrity_result == "ok":
            print("‚úÖ Database integrity check passed")
            return True
        else:
            print(f"‚ùå Database corruption detected: {integrity_result}")
            return False

# 2. Repair database
def repair_database():
    """S·ª≠a ch·ªØa database"""
    from app.database import engine
    
    with engine.connect() as conn:
        # Vacuum database
        conn.execute(text("VACUUM"))
        
        # Rebuild indexes
        conn.execute(text("REINDEX"))
        
        # Analyze database
        conn.execute(text("ANALYZE"))
        
        conn.commit()
    
    print("‚úÖ Database repair completed")

# 3. Restore from backup
def restore_from_backup(backup_path: str):
    """Kh√¥i ph·ª•c t·ª´ backup"""
    import shutil
    
    if not os.path.exists(backup_path):
        raise FileNotFoundError(f"Backup not found: {backup_path}")
    
    # Stop application
    # ... stop application code ...
    
    # Restore database
    shutil.copy2(backup_path, "./data/sales_management.db")
    
    print(f"‚úÖ Database restored from: {backup_path}")
```

### 4.2 Data Inconsistency

**Tri·ªáu ch·ª©ng:**
- Duplicate records
- Missing relationships
- Invalid data

**Gi·∫£i ph√°p:**
```python
# 1. Find and fix duplicates
def fix_duplicate_skus(db: Session):
    """T√¨m v√† s·ª≠a SKU tr√πng l·∫∑p"""
    # T√¨m SKU tr√πng l·∫∑p
    duplicates = db.execute(text("""
        SELECT sku, COUNT(*) as count
        FROM products
        GROUP BY sku
        HAVING COUNT(*) > 1
    """)).fetchall()
    
    for sku, count in duplicates:
        print(f"Found {count} duplicates for SKU: {sku}")
        
        # Gi·ªØ record m·ªõi nh·∫•t, x√≥a c√°c record c≈©
        products = db.query(Product).filter(Product.sku == sku).order_by(
            Product.created_at.desc()
        ).all()
        
        # X√≥a t·∫•t c·∫£ tr·ª´ record ƒë·∫ßu ti√™n
        for product in products[1:]:
            db.delete(product)
    
    db.commit()
    print(f"Fixed {len(duplicates)} duplicate SKUs")

# 2. Validate relationships
def validate_relationships(db: Session):
    """Ki·ªÉm tra t√≠nh to√†n v·∫πn relationships"""
    # T√¨m logs kh√¥ng c√≥ product
    orphaned_logs = db.query(ProductLog).outerjoin(Product).filter(
        Product.id.is_(None)
    ).all()
    
    if orphaned_logs:
        print(f"Found {len(orphaned_logs)} orphaned logs")
        for log in orphaned_logs:
            db.delete(log)
        
        db.commit()
    
    # T√¨m products kh√¥ng c√≥ logs
    products_without_logs = db.query(Product).outerjoin(ProductLog).filter(
        ProductLog.id.is_(None)
    ).all()
    
    print(f"Found {len(products_without_logs)} products without logs")
```

## 5. Backup v√† Recovery Issues

### 5.1 Backup Failures

**L·ªói:**
- Backup file corrupted
- Insufficient disk space
- Permission denied

**Gi·∫£i ph√°p:**
```python
# 1. Safe backup with verification
def safe_backup():
    """Backup an to√†n v·ªõi verification"""
    import shutil
    from datetime import datetime
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"backups/sales_management_{timestamp}.db"
    
    try:
        # T·∫°o th∆∞ m·ª•c backup
        os.makedirs("backups", exist_ok=True)
        
        # Copy database
        shutil.copy2("./data/sales_management.db", backup_path)
        
        # Verify backup
        if verify_backup(backup_path):
            print(f"‚úÖ Backup created successfully: {backup_path}")
            return backup_path
        else:
            os.remove(backup_path)
            raise Exception("Backup verification failed")
            
    except Exception as e:
        print(f"‚ùå Backup failed: {e}")
        return None

# 2. Check disk space
def check_disk_space():
    """Ki·ªÉm tra dung l∆∞·ª£ng ·ªï ƒëƒ©a"""
    import shutil
    
    total, used, free = shutil.disk_usage("./data")
    free_gb = free / (1024**3)
    
    if free_gb < 1.0:  # √çt h∆°n 1GB
        print(f"‚ö†Ô∏è Low disk space: {free_gb:.2f} GB free")
        return False
    
    return True
```

### 5.2 Recovery Failures

**L·ªói:**
- Backup file not found
- Restore process failed
- Data loss

**Gi·∫£i ph√°p:**
```python
# 1. Automated recovery
def automated_recovery():
    """T·ª± ƒë·ªông kh√¥i ph·ª•c khi c√≥ s·ª± c·ªë"""
    # Ki·ªÉm tra database integrity
    if not check_database_integrity():
        print("üö® Database corruption detected!")
        
        # T√¨m backup g·∫ßn nh·∫•t
        backup_files = glob.glob("backups/sales_management_*.db")
        if backup_files:
            latest_backup = max(backup_files, key=os.path.getctime)
            print(f"üîÑ Attempting recovery from: {latest_backup}")
            
            if restore_from_backup(latest_backup):
                print("‚úÖ Recovery completed successfully")
                return True
        
        print("‚ùå No valid backup found for recovery")
        return False
    
    return True

# 2. Multiple backup locations
def backup_to_multiple_locations():
    """Backup ƒë·∫øn nhi·ªÅu v·ªã tr√≠"""
    backup_paths = [
        "backups/local/",
        "backups/network/",
        "backups/cloud/"
    ]
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"sales_management_{timestamp}.db"
    
    for backup_dir in backup_paths:
        try:
            os.makedirs(backup_dir, exist_ok=True)
            backup_path = os.path.join(backup_dir, backup_name)
            shutil.copy2("./data/sales_management.db", backup_path)
            print(f"‚úÖ Backup to {backup_path}")
        except Exception as e:
            print(f"‚ùå Backup to {backup_dir} failed: {e}")
```

## 6. Monitoring v√† Alerting

### 6.1 Database Health Monitoring

```python
class DatabaseMonitor:
    def __init__(self):
        self.alert_thresholds = {
            "file_size_mb": 100,
            "log_count": 10000,
            "slow_query_threshold": 1.0
        }
    
    def check_database_health(self):
        """Ki·ªÉm tra s·ª©c kh·ªèe database"""
        issues = []
        
        # Ki·ªÉm tra file size
        db_size = os.path.getsize("./data/sales_management.db") / (1024 * 1024)
        if db_size > self.alert_thresholds["file_size_mb"]:
            issues.append(f"Database file too large: {db_size:.2f} MB")
        
        # Ki·ªÉm tra log count
        from app.database import SessionLocal
        db = SessionLocal()
        try:
            log_count = db.query(ProductLog).count()
            if log_count > self.alert_thresholds["log_count"]:
                issues.append(f"Too many logs: {log_count}")
        finally:
            db.close()
        
        # Ki·ªÉm tra integrity
        if not check_database_integrity():
            issues.append("Database integrity check failed")
        
        return issues
    
    def send_alert(self, issues: list):
        """G·ª≠i c·∫£nh b√°o"""
        if issues:
            message = "Database Health Alert:\n" + "\n".join(issues)
            print(f"üö® {message}")
            # G·ª≠i email, Slack, etc.
```

### 6.2 Performance Monitoring

```python
def monitor_database_performance():
    """Monitor performance database"""
    from app.database import engine
    
    with engine.connect() as conn:
        # Ki·ªÉm tra cache hit ratio
        result = conn.execute(text("PRAGMA cache_stats"))
        cache_stats = result.fetchone()
        
        # Ki·ªÉm tra page count
        result = conn.execute(text("PRAGMA page_count"))
        page_count = result.fetchone()[0]
        
        # Ki·ªÉm tra fragmentation
        result = conn.execute(text("PRAGMA page_count"))
        total_pages = result.fetchone()[0]
        
        result = conn.execute(text("PRAGMA freelist_count"))
        free_pages = result.fetchone()[0]
        
        fragmentation = (free_pages / total_pages) * 100 if total_pages > 0 else 0
        
        print(f"Database Performance:")
        print(f"  - Cache hits: {cache_stats[0]}")
        print(f"  - Total pages: {total_pages}")
        print(f"  - Fragmentation: {fragmentation:.2f}%")
        
        if fragmentation > 20:
            print("‚ö†Ô∏è High fragmentation detected - consider VACUUM")
``` 